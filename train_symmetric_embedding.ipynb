{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "680a2ed7",
   "metadata": {},
   "source": [
    "\n",
    "# Symmetric Function Embedding (PyTorch)\n",
    "\n",
    "This notebook trains a tiny encoder–decoder MLP on a **rotationally symmetric** target function $f(\\mathbf{x}) = \\sin(|\\mathbf{x}|)$.\n",
    "\n",
    "It includes a low-dimensional **embedding bottleneck** you can analyze, and saves:\n",
    "- `toy_symmetry_model.pt` – the trained model (state dict + metadata)\n",
    "- `embeddings_grid.npz` – a polar grid of inputs with the model's embeddings and predictions\n",
    "\n",
    "> Tip: tweak `cfg.embed_dim` and the target function to explore different symmetries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e06efc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.8.0\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Setup & Config\n",
    "# --------------------\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "if getattr(torch.backends, \"mps\", None) is not None and torch.backends.mps.is_available() and getattr(torch.backends.mps, 'is_built', lambda: True)():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "_run_path_number = -1\n",
    "_run_path = ''\n",
    "while os.path.exists(_run_path) or _run_path_number < 0:\n",
    "    _run_path_number += 1\n",
    "    _run_path = os.path.join('runs', f'symmetry_run_{_run_path_number}')\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    seed: int = 42\n",
    "    n_train: int = 50_000\n",
    "    n_val: int = 5_000\n",
    "    batch_size: int = 256\n",
    "    lr: float = 1e-3\n",
    "    epochs: int = 25\n",
    "    hidden: int = 64\n",
    "    embed_dim: int = 4   # embedding space size to analyze\n",
    "    data_range: float = 3.0  # sample x,y uniformly in [-R, R]\n",
    "    device: torch.device = device\n",
    "    model_path: str = os.path.join(_run_path, \"model.pt\")\n",
    "    emb_grid_path: str = os.path.join(_run_path, \"embeddings_grid.npz\")\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(cfg.seed)\n",
    "\n",
    "# generate a small random suffix; use integer literal for upper bound to avoid TypeError\n",
    "writer = SummaryWriter(log_dir=_run_path)\n",
    "writer.add_text('config', str(dict(hidden=cfg.hidden, embed_dim=cfg.embed_dim, data_range=cfg.data_range, seed=cfg.seed)))\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41d53536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: online sampling, 50000 samples/epoch; Validation: 5000 samples\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Data: rotational symmetry (online training)\n",
    "# Target: f(x, y) = sin(sqrt(x^2 + y^2))\n",
    "# --------------------\n",
    "class RandomXYDataset(torch.utils.data.IterableDataset):\n",
    "    \"\"\"Iterable dataset that samples (x,y) pairs uniformly in [-R, R]^2 each epoch.\"\"\"\n",
    "    def __init__(self, n, R):\n",
    "        super().__init__()\n",
    "        self.n = int(n)\n",
    "        self.R = float(R)\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Generate all samples for this epoch and yield them in random order.\n",
    "        xy = np.random.uniform(-self.R, self.R, size=(self.n, 2)).astype(np.float32)\n",
    "        r = np.linalg.norm(xy, axis=1, keepdims=True).astype(np.float32)\n",
    "        y = np.sin(r).astype(np.float32)\n",
    "\n",
    "        # Optionally shuffle order so batches vary each epoch\n",
    "        idx = np.arange(self.n)\n",
    "        np.random.shuffle(idx)\n",
    "        for i in idx:\n",
    "            yield torch.from_numpy(xy[i]), torch.from_numpy(y[i])\n",
    "\n",
    "# Validation set remains pre-sampled for stable evaluation\n",
    "x_val = np.random.uniform(-cfg.data_range, cfg.data_range, size=(cfg.n_val, 2)).astype(np.float32)\n",
    "r_val = np.linalg.norm(x_val, axis=1, keepdims=True).astype(np.float32)\n",
    "y_val = np.sin(r_val).astype(np.float32)\n",
    "\n",
    "train_dataset = RandomXYDataset(cfg.n_train, cfg.data_range)\n",
    "train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=False, drop_last=True)\n",
    "val_loader = DataLoader(TensorDataset(torch.from_numpy(x_val), torch.from_numpy(y_val)), batch_size=1024, shuffle=False)\n",
    "\n",
    "# Print dataset sizes for confirmation\n",
    "print(f\"Training: online sampling, {cfg.n_train} samples/epoch; Validation: {len(x_val)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6b0cc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SymmetricToyNet(\n",
       "  (enc): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): GELU(approximate='none')\n",
       "  )\n",
       "  (embed): Linear(in_features=64, out_features=4, bias=True)\n",
       "  (dec): Sequential(\n",
       "    (0): GELU(approximate='none')\n",
       "    (1): Linear(in_features=4, out_features=64, bias=True)\n",
       "    (2): GELU(approximate='none')\n",
       "    (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --------------------\n",
    "# Model: Encoder -> Embedding -> Decoder\n",
    "# --------------------\n",
    "class SymmetricToyNet(nn.Module):\n",
    "    def __init__(self, in_dim=2, hidden=64, embed_dim=2):\n",
    "        super().__init__()\n",
    "        # encoder\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        # embedding (bottleneck)\n",
    "        self.embed = nn.Linear(hidden, embed_dim)\n",
    "\n",
    "        # decoder\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim, hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden, 1),\n",
    "        )\n",
    "\n",
    "        # Kaiming init\n",
    "        def init(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight, a=math.sqrt(5))\n",
    "                if m.bias is not None:\n",
    "                    fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n",
    "                    bound = 1 / math.sqrt(fan_in)\n",
    "                    nn.init.uniform_(m.bias, -bound, bound)\n",
    "        self.apply(init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.enc(x)\n",
    "        z = self.embed(h)\n",
    "        out = self.dec(z)\n",
    "        return out, z\n",
    "\n",
    "model = SymmetricToyNet(hidden=cfg.hidden, embed_dim=cfg.embed_dim).to(cfg.device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dbe778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.76660204 0.397386   1.4832675  0.7541363 ]\n",
      " [1.5072536  2.7673707  0.5099053  0.3163967 ]\n",
      " [0.74721813 0.38037446 1.404191   0.7703118 ]\n",
      " ...\n",
      " [0.78408617 0.7962326  1.3488846  0.75545484]\n",
      " [0.72979206 0.01133008 1.4043319  0.73903817]\n",
      " [0.90415114 1.1851424  1.6042862  0.7739054 ]]\n",
      "Epoch 01/25 | val MSE: 0.003577\n",
      "[[2.3480918  2.5691285  2.056397   0.97382075]\n",
      " [1.0164411  0.47309586 1.3806063  0.9433281 ]\n",
      " [2.2531257  2.803103   1.8752717  1.0170593 ]\n",
      " ...\n",
      " [2.591055   2.3546014  1.5087079  1.0067024 ]\n",
      " [1.5683738  1.2432367  1.5308281  1.0022707 ]\n",
      " [2.0241208  1.7844038  1.5353068  1.0841305 ]]\n",
      "Epoch 01/25 | val MSE: 0.003577\n",
      "[[2.3480918  2.5691285  2.056397   0.97382075]\n",
      " [1.0164411  0.47309586 1.3806063  0.9433281 ]\n",
      " [2.2531257  2.803103   1.8752717  1.0170593 ]\n",
      " ...\n",
      " [2.591055   2.3546014  1.5087079  1.0067024 ]\n",
      " [1.5683738  1.2432367  1.5308281  1.0022707 ]\n",
      " [2.0241208  1.7844038  1.5353068  1.0841305 ]]\n",
      "[[2.8172402  2.8726158  2.4462614  1.3752297 ]\n",
      " [3.1162019  3.6734495  2.1058867  1.2046729 ]\n",
      " [3.576462   4.0331464  2.6585226  1.3822592 ]\n",
      " ...\n",
      " [3.3203535  3.985652   2.278682   1.2212964 ]\n",
      " [0.85487074 0.3610004  1.2713045  1.1041802 ]\n",
      " [2.1385899  2.0036035  1.9132386  1.3178366 ]]\n",
      "[[2.8172402  2.8726158  2.4462614  1.3752297 ]\n",
      " [3.1162019  3.6734495  2.1058867  1.2046729 ]\n",
      " [3.576462   4.0331464  2.6585226  1.3822592 ]\n",
      " ...\n",
      " [3.3203535  3.985652   2.278682   1.2212964 ]\n",
      " [0.85487074 0.3610004  1.2713045  1.1041802 ]\n",
      " [2.1385899  2.0036035  1.9132386  1.3178366 ]]\n",
      "[[ 3.1867056   3.5298448   2.1844664   1.5515023 ]\n",
      " [ 3.840285    4.9591813   2.1691775   1.3703549 ]\n",
      " [ 2.4050117   1.7552104   1.7248402   1.651981  ]\n",
      " ...\n",
      " [ 3.9514906   4.158375    2.934363    1.7077307 ]\n",
      " [ 0.33596206 -0.02830497  1.136091    1.0480188 ]\n",
      " [ 0.98364484  0.5300654   1.4986126   1.211531  ]]\n",
      "[[ 3.1867056   3.5298448   2.1844664   1.5515023 ]\n",
      " [ 3.840285    4.9591813   2.1691775   1.3703549 ]\n",
      " [ 2.4050117   1.7552104   1.7248402   1.651981  ]\n",
      " ...\n",
      " [ 3.9514906   4.158375    2.934363    1.7077307 ]\n",
      " [ 0.33596206 -0.02830497  1.136091    1.0480188 ]\n",
      " [ 0.98364484  0.5300654   1.4986126   1.211531  ]]\n",
      "[[1.3752242 0.7952402 1.4986789 1.667591 ]\n",
      " [3.1442356 2.3636425 1.9835464 2.0186431]\n",
      " [4.1711903 4.1088448 2.646552  1.8521159]\n",
      " ...\n",
      " [2.11489   1.3706381 1.7580774 1.6897599]\n",
      " [4.8100524 4.387613  2.2216878 2.0688465]\n",
      " [1.80102   1.0895882 1.6572504 1.6160536]]\n",
      "[[1.3752242 0.7952402 1.4986789 1.667591 ]\n",
      " [3.1442356 2.3636425 1.9835464 2.0186431]\n",
      " [4.1711903 4.1088448 2.646552  1.8521159]\n",
      " ...\n",
      " [2.11489   1.3706381 1.7580774 1.6897599]\n",
      " [4.8100524 4.387613  2.2216878 2.0688465]\n",
      " [1.80102   1.0895882 1.6572504 1.6160536]]\n",
      "[[2.286893  1.5336488 2.0896764 1.6374927]\n",
      " [3.4738014 2.8709862 2.4604619 1.924523 ]\n",
      " [2.6392128 1.7077795 1.8967485 2.059037 ]\n",
      " ...\n",
      " [4.9641953 4.842832  3.0921888 1.8277457]\n",
      " [3.5016963 2.9885705 2.4257512 1.9180199]\n",
      " [3.1268017 2.4647796 2.4307814 1.7545409]]\n",
      "[[2.286893  1.5336488 2.0896764 1.6374927]\n",
      " [3.4738014 2.8709862 2.4604619 1.924523 ]\n",
      " [2.6392128 1.7077795 1.8967485 2.059037 ]\n",
      " ...\n",
      " [4.9641953 4.842832  3.0921888 1.8277457]\n",
      " [3.5016963 2.9885705 2.4257512 1.9180199]\n",
      " [3.1268017 2.4647796 2.4307814 1.7545409]]\n",
      "[[3.0034688  2.1361024  2.2596679  1.7680893 ]\n",
      " [1.5592535  0.76807535 1.6437707  1.6602993 ]\n",
      " [2.6878643  1.736269   2.0976217  1.8595487 ]\n",
      " ...\n",
      " [4.0480466  2.923299   2.3600388  2.360462  ]\n",
      " [1.9891764  1.083476   1.7181474  1.8877782 ]\n",
      " [2.7556107  1.8768835  2.2850995  1.7452774 ]]\n",
      "[[3.0034688  2.1361024  2.2596679  1.7680893 ]\n",
      " [1.5592535  0.76807535 1.6437707  1.6602993 ]\n",
      " [2.6878643  1.736269   2.0976217  1.8595487 ]\n",
      " ...\n",
      " [4.0480466  2.923299   2.3600388  2.360462  ]\n",
      " [1.9891764  1.083476   1.7181474  1.8877782 ]\n",
      " [2.7556107  1.8768835  2.2850995  1.7452774 ]]\n",
      "[[5.1202035 5.051063  2.6478179 1.8644502]\n",
      " [4.660002  3.9198227 2.77981   1.9573543]\n",
      " [5.6634965 5.1015277 3.4032118 2.0444868]\n",
      " ...\n",
      " [4.5008874 3.825381  2.8085277 2.07732  ]\n",
      " [3.3972344 2.4257426 2.3584182 1.9897532]\n",
      " [4.177625  3.51375   2.4752142 1.9943061]]\n",
      "[[5.1202035 5.051063  2.6478179 1.8644502]\n",
      " [4.660002  3.9198227 2.77981   1.9573543]\n",
      " [5.6634965 5.1015277 3.4032118 2.0444868]\n",
      " ...\n",
      " [4.5008874 3.825381  2.8085277 2.07732  ]\n",
      " [3.3972344 2.4257426 2.3584182 1.9897532]\n",
      " [4.177625  3.51375   2.4752142 1.9943061]]\n",
      "[[3.1091294 2.049419  2.2915986 1.8450258]\n",
      " [4.657314  3.7362776 2.5305455 2.149213 ]\n",
      " [5.4374967 4.5276437 2.9523222 2.403385 ]\n",
      " ...\n",
      " [5.5794883 4.792964  3.4459794 2.0503488]\n",
      " [2.1870906 1.162256  1.9073757 1.8438176]\n",
      " [6.4419847 5.3322544 2.7093043 2.5245216]]\n",
      "[[3.1091294 2.049419  2.2915986 1.8450258]\n",
      " [4.657314  3.7362776 2.5305455 2.149213 ]\n",
      " [5.4374967 4.5276437 2.9523222 2.403385 ]\n",
      " ...\n",
      " [5.5794883 4.792964  3.4459794 2.0503488]\n",
      " [2.1870906 1.162256  1.9073757 1.8438176]\n",
      " [6.4419847 5.3322544 2.7093043 2.5245216]]\n",
      "Epoch 05/25 | val MSE: 0.000138\n",
      "[[6.276782   5.6864285  3.330317   2.026043  ]\n",
      " [5.642133   5.1401253  2.7046914  2.031496  ]\n",
      " [1.5602751  0.70266813 1.6345739  1.807957  ]\n",
      " ...\n",
      " [4.234003   3.2550068  2.7213035  1.9183016 ]\n",
      " [4.6651845  3.5367818  2.7684004  2.3572893 ]\n",
      " [5.6705217  4.3410997  2.7264595  2.6054509 ]]\n",
      "Epoch 05/25 | val MSE: 0.000138\n",
      "[[6.276782   5.6864285  3.330317   2.026043  ]\n",
      " [5.642133   5.1401253  2.7046914  2.031496  ]\n",
      " [1.5602751  0.70266813 1.6345739  1.807957  ]\n",
      " ...\n",
      " [4.234003   3.2550068  2.7213035  1.9183016 ]\n",
      " [4.6651845  3.5367818  2.7684004  2.3572893 ]\n",
      " [5.6705217  4.3410997  2.7264595  2.6054509 ]]\n",
      "[[3.4928136  2.2088392  2.282161   2.114404  ]\n",
      " [4.533222   3.4852984  2.8131444  2.1241252 ]\n",
      " [4.6570873  3.6604557  2.5516617  2.1352901 ]\n",
      " ...\n",
      " [2.4488351  1.301067   2.0011396  1.9362957 ]\n",
      " [1.7947562  0.83394504 1.7187334  1.8901865 ]\n",
      " [5.0160265  4.3749623  2.7147954  2.0262153 ]]\n",
      "[[3.4928136  2.2088392  2.282161   2.114404  ]\n",
      " [4.533222   3.4852984  2.8131444  2.1241252 ]\n",
      " [4.6570873  3.6604557  2.5516617  2.1352901 ]\n",
      " ...\n",
      " [2.4488351  1.301067   2.0011396  1.9362957 ]\n",
      " [1.7947562  0.83394504 1.7187334  1.8901865 ]\n",
      " [5.0160265  4.3749623  2.7147954  2.0262153 ]]\n",
      "[[6.6585307 6.0349417 3.1957552 1.803294 ]\n",
      " [6.2535214 4.831785  2.6828334 2.5778983]\n",
      " [3.2529304 1.949954  2.2255864 2.0662172]\n",
      " ...\n",
      " [3.129416  1.9361231 2.3583188 1.9683396]\n",
      " [3.6021497 2.284185  2.3076968 2.112676 ]\n",
      " [5.4316382 4.5435038 2.9271693 1.9144045]]\n",
      "[[6.6585307 6.0349417 3.1957552 1.803294 ]\n",
      " [6.2535214 4.831785  2.6828334 2.5778983]\n",
      " [3.2529304 1.949954  2.2255864 2.0662172]\n",
      " ...\n",
      " [3.129416  1.9361231 2.3583188 1.9683396]\n",
      " [3.6021497 2.284185  2.3076968 2.112676 ]\n",
      " [5.4316382 4.5435038 2.9271693 1.9144045]]\n",
      "[[4.8618493 3.9081216 2.8576546 2.1459823]\n",
      " [6.3256783 5.534881  3.3617895 2.0454152]\n",
      " [4.140165  2.9671118 2.7084298 2.0677722]\n",
      " ...\n",
      " [4.0434737 2.5253394 2.3945248 2.2980373]\n",
      " [3.811697  2.3820539 2.460608  2.321892 ]\n",
      " [3.5366564 2.119023  2.2668524 2.1581383]]\n",
      "[[4.8618493 3.9081216 2.8576546 2.1459823]\n",
      " [6.3256783 5.534881  3.3617895 2.0454152]\n",
      " [4.140165  2.9671118 2.7084298 2.0677722]\n",
      " ...\n",
      " [4.0434737 2.5253394 2.3945248 2.2980373]\n",
      " [3.811697  2.3820539 2.460608  2.321892 ]\n",
      " [3.5366564 2.119023  2.2668524 2.1581383]]\n",
      "[[6.6217666  5.875898   3.3446174  2.004208  ]\n",
      " [5.1100965  4.0105815  2.6129112  2.1553154 ]\n",
      " [1.8739009  0.84087837 1.688389   2.0958629 ]\n",
      " ...\n",
      " [5.963489   4.98398    3.424149   2.1021512 ]\n",
      " [4.3827596  3.255211   2.6857631  1.9487021 ]\n",
      " [6.5379224  6.289077   2.8769703  1.8150175 ]]\n",
      "[[6.6217666  5.875898   3.3446174  2.004208  ]\n",
      " [5.1100965  4.0105815  2.6129112  2.1553154 ]\n",
      " [1.8739009  0.84087837 1.688389   2.0958629 ]\n",
      " ...\n",
      " [5.963489   4.98398    3.424149   2.1021512 ]\n",
      " [4.3827596  3.255211   2.6857631  1.9487021 ]\n",
      " [6.5379224  6.289077   2.8769703  1.8150175 ]]\n",
      "[[3.426739  1.8795539 2.2002482 2.3530579]\n",
      " [7.160992  5.641983  2.7687163 2.5326085]\n",
      " [3.6879308 2.1585572 2.3005447 2.2245104]\n",
      " ...\n",
      " [2.7744246 1.4587042 2.1353428 1.9816344]\n",
      " [5.3532705 4.2053857 2.9091358 2.2897925]\n",
      " [5.2303796 3.5284865 2.5885825 2.5974085]]\n",
      "[[3.426739  1.8795539 2.2002482 2.3530579]\n",
      " [7.160992  5.641983  2.7687163 2.5326085]\n",
      " [3.6879308 2.1585572 2.3005447 2.2245104]\n",
      " ...\n",
      " [2.7744246 1.4587042 2.1353428 1.9816344]\n",
      " [5.3532705 4.2053857 2.9091358 2.2897925]\n",
      " [5.2303796 3.5284865 2.5885825 2.5974085]]\n",
      "[[3.8560324 2.6065388 2.555049  1.950811 ]\n",
      " [4.141877  2.47752   2.4189944 2.3626785]\n",
      " [6.3546505 4.7633915 2.8471293 2.5232992]\n",
      " ...\n",
      " [5.86812   4.3226824 2.8531587 2.6316302]\n",
      " [5.334303  3.7190905 2.6805954 2.4599001]\n",
      " [6.178259  4.6554327 2.8289232 2.4658847]]\n",
      "[[3.8560324 2.6065388 2.555049  1.950811 ]\n",
      " [4.141877  2.47752   2.4189944 2.3626785]\n",
      " [6.3546505 4.7633915 2.8471293 2.5232992]\n",
      " ...\n",
      " [5.86812   4.3226824 2.8531587 2.6316302]\n",
      " [5.334303  3.7190905 2.6805954 2.4599001]\n",
      " [6.178259  4.6554327 2.8289232 2.4658847]]\n",
      "[[6.1286263 5.140358  3.4389277 2.0371299]\n",
      " [5.382775  3.6112573 2.6395106 2.5720975]\n",
      " [1.4909115 0.5713579 1.6217494 1.9257159]\n",
      " ...\n",
      " [6.1493483 5.160046  3.355256  2.0986679]\n",
      " [4.909261  3.2113636 2.5878077 2.4385676]\n",
      " [2.5754428 1.3291115 2.0966845 2.0017529]]\n",
      "[[6.1286263 5.140358  3.4389277 2.0371299]\n",
      " [5.382775  3.6112573 2.6395106 2.5720975]\n",
      " [1.4909115 0.5713579 1.6217494 1.9257159]\n",
      " ...\n",
      " [6.1493483 5.160046  3.355256  2.0986679]\n",
      " [4.909261  3.2113636 2.5878077 2.4385676]\n",
      " [2.5754428 1.3291115 2.0966845 2.0017529]]\n",
      "[[4.7467275 3.3714542 2.74055   2.2912676]\n",
      " [4.1953254 2.7624977 2.6061811 2.221242 ]\n",
      " [2.5857644 1.3201996 2.1212676 1.9543027]\n",
      " ...\n",
      " [4.2890635 3.0052154 2.8164163 2.0232506]\n",
      " [3.8443773 2.4558213 2.556801  2.0878975]\n",
      " [4.6896343 3.429676  2.8299348 2.180696 ]]\n",
      "[[4.7467275 3.3714542 2.74055   2.2912676]\n",
      " [4.1953254 2.7624977 2.6061811 2.221242 ]\n",
      " [2.5857644 1.3201996 2.1212676 1.9543027]\n",
      " ...\n",
      " [4.2890635 3.0052154 2.8164163 2.0232506]\n",
      " [3.8443773 2.4558213 2.556801  2.0878975]\n",
      " [4.6896343 3.429676  2.8299348 2.180696 ]]\n",
      "[[6.0207148 4.578752  2.7617674 2.2892127]\n",
      " [5.556906  4.390263  3.266522  2.1303582]\n",
      " [4.985517  3.1929202 2.5910451 2.4565146]\n",
      " ...\n",
      " [5.8150063 4.8392744 3.047819  1.9199659]\n",
      " [6.1385417 4.768559  2.77532   2.249847 ]\n",
      " [7.151646  5.5089135 2.8087218 2.5365386]]\n",
      "[[6.0207148 4.578752  2.7617674 2.2892127]\n",
      " [5.556906  4.390263  3.266522  2.1303582]\n",
      " [4.985517  3.1929202 2.5910451 2.4565146]\n",
      " ...\n",
      " [5.8150063 4.8392744 3.047819  1.9199659]\n",
      " [6.1385417 4.768559  2.77532   2.249847 ]\n",
      " [7.151646  5.5089135 2.8087218 2.5365386]]\n",
      "Epoch 10/25 | val MSE: 0.000093\n",
      "Epoch 10/25 | val MSE: 0.000093\n",
      "[[7.861866  6.2480154 2.7368307 2.367407 ]\n",
      " [2.4990172 1.1499604 1.8905358 2.1932414]\n",
      " [5.04389   3.8412895 2.8267365 2.0595381]\n",
      " ...\n",
      " [4.7408347 3.3314817 2.5299592 2.144743 ]\n",
      " [7.0883565 6.248311  3.3415937 1.9674042]\n",
      " [6.1119184 5.0816774 3.3794813 2.0270536]]\n",
      "[[7.861866  6.2480154 2.7368307 2.367407 ]\n",
      " [2.4990172 1.1499604 1.8905358 2.1932414]\n",
      " [5.04389   3.8412895 2.8267365 2.0595381]\n",
      " ...\n",
      " [4.7408347 3.3314817 2.5299592 2.144743 ]\n",
      " [7.0883565 6.248311  3.3415937 1.9674042]\n",
      " [6.1119184 5.0816774 3.3794813 2.0270536]]\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Training\n",
    "# --------------------\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=1e-4)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    total, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(cfg.device)\n",
    "            yb = yb.to(cfg.device)\n",
    "            pred, _ = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            total += loss.item() * xb.size(0)\n",
    "            n += xb.size(0)\n",
    "    return total / n\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "for epoch in range(1, cfg.epochs + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    batch_count = 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(cfg.device)      # [B,2]\n",
    "        yb = yb.to(cfg.device)      # [B,1]\n",
    "        pred, z = model(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        global_step += 1\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "        batch_count += xb.size(0)\n",
    "        writer.add_scalar('train/batch_loss', loss.item(), global_step)\n",
    "        if global_step % 100 == 0:\n",
    "            writer.add_histogram('embed/batch', z.detach().cpu().numpy(), global_step)\n",
    "\n",
    "    epoch_loss = running_loss / batch_count if batch_count else 0.0\n",
    "    writer.add_scalar('train/epoch_loss', epoch_loss, epoch)\n",
    "\n",
    "    val_loss = evaluate()\n",
    "    best_val = min(best_val, val_loss)\n",
    "\n",
    "    writer.add_scalar('val/epoch_loss', val_loss, epoch)\n",
    "    for i, param_group in enumerate(opt.param_groups):\n",
    "        writer.add_scalar(f'lr/group_{i}', param_group.get('lr', 0.0), epoch)\n",
    "\n",
    "    if epoch % 5 == 0 or epoch == 1 or epoch == cfg.epochs:\n",
    "        print(f\"Epoch {epoch:02d}/{cfg.epochs} | val MSE: {val_loss:.6f}\")\n",
    "\n",
    "print(f\"Best val MSE: {best_val:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75d0738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: /Users/noah-everett/Documents/Research/Embedding-Analysis/runs/symmetry_run_1/model.pt\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Save model + handy metadata\n",
    "# --------------------\n",
    "payload = {\n",
    "    \"state_dict\": model.state_dict(),\n",
    "    \"config\": {\n",
    "        \"hidden\": cfg.hidden,\n",
    "        \"embed_dim\": cfg.embed_dim,\n",
    "        \"target_fn\": \"f(x,y) = sin(||[x,y]||)\",\n",
    "        \"data_range\": cfg.data_range,\n",
    "        \"normalization\": \"none\",\n",
    "        \"seed\": cfg.seed,\n",
    "    },\n",
    "    \"model_class\": \"SymmetricToyNet\",\n",
    "}\n",
    "torch.save(payload, cfg.model_path)\n",
    "print(f\"Saved model to: {os.path.abspath(cfg.model_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38dc4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embedding grid to: /Users/noah-everett/Documents/Research/Embedding-Analysis/runs/symmetry_run_1/embeddings_grid.npz\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Save embeddings for a polar grid (for downstream analysis)\n",
    "# --------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # build a polar grid; map to xy; get embeddings z\n",
    "    radii = np.linspace(0.0, cfg.data_range * math.sqrt(2), 80).astype(np.float32)\n",
    "    thetas = np.linspace(0.0, 2 * math.pi, 128, endpoint=False).astype(np.float32)\n",
    "    R, T = np.meshgrid(radii, thetas, indexing='ij')\n",
    "    X = (R * np.cos(T)).reshape(-1)\n",
    "    Y = (R * np.sin(T)).reshape(-1)\n",
    "    XY = np.stack([X, Y], axis=1).astype(np.float32)\n",
    "\n",
    "    xb = torch.from_numpy(XY).to(cfg.device)\n",
    "    pred, z = model(xb)\n",
    "    pred = pred.squeeze(-1).cpu().numpy()\n",
    "    Z = z.cpu().numpy()\n",
    "\n",
    "    try:\n",
    "        radii_flat = R.reshape(-1)\n",
    "        writer.add_embedding(torch.from_numpy(Z), metadata=[str(float(r)) for r in radii_flat], global_step=0, tag='embeddings/grid')\n",
    "        if cfg.embed_dim == 2:\n",
    "            fig, ax = plt.subplots(figsize=(6, 6))\n",
    "            sc = ax.scatter(Z[:, 0], Z[:, 1], c=radii_flat, s=5, cmap='viridis')\n",
    "            ax.set_title('Embeddings (colored by radius)')\n",
    "            ax.set_xlabel('z0')\n",
    "            ax.set_ylabel('z1')\n",
    "            plt.colorbar(sc, ax=ax, label='radius')\n",
    "            writer.add_figure('embeddings/2d_scatter', fig)\n",
    "            plt.close(fig)\n",
    "    except Exception as e:\n",
    "        print('Warning: failed to log embeddings to TensorBoard:', e)\n",
    "\n",
    "# Save everything needed for downstream math/plots\n",
    "np.savez_compressed(\n",
    "    cfg.emb_grid_path,\n",
    "    xy=XY,               # [N,2] positions in input space\n",
    "    z=Z,                 # [N,embed_dim] embeddings\n",
    "    pred=pred,           # [N] predicted f(x)\n",
    "    radii=R.reshape(-1), # [N] radius used to generate XY\n",
    "    thetas=T.reshape(-1) # [N] angle used to generate XY\n",
    ")\n",
    "print(f\"Saved embedding grid to: {os.path.abspath(cfg.emb_grid_path)}\")\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_3_11_5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

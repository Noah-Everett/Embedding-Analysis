{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "680a2ed7",
   "metadata": {},
   "source": [
    "# General Function Embedding (PyTorch)\n",
    "\n",
    "This notebook is now generalized to learn any target function f: R^{in_dim} -> R^{out_dim} using a compact bottleneck (latent) representation.\n",
    "\n",
    "What you can customize quickly:\n",
    "- Input size (in_dim), output size (out_dim), and latent size (embed_dim)\n",
    "- Target function via a simple Python callable\n",
    "- Model depth/width and activations\n",
    "- Sampling domain and dataset sizes\n",
    "\n",
    "Artifacts saved per run:\n",
    "- model.pt – trained weights + config metadata\n",
    "- embeddings_probe.npz – random probe inputs with embeddings and predictions\n",
    "\n",
    "Tip: Edit the `target_fn` in the setup cell to learn any function you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06efc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.8.0\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Setup & Config\n",
    "# --------------------\n",
    "import math\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from lib import (\n",
    "    BottleneckMLP,\n",
    "    OnlineFunctionDataset,\n",
    "    make_fixed_val_dataset,\n",
    "    train_model,\n",
    "    evaluate,\n",
    "    get_device,\n",
    "    set_seed,\n",
    "    next_run_path,\n",
    ")\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "device = get_device()\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Create a unique run folder (keeps your old results intact)\n",
    "_run_path = next_run_path(base_dir='runs', prefix='symmetry_run_')\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Data/function\n",
    "    in_dim: int = 2\n",
    "    out_dim: int = 1\n",
    "    embed_dim: int = 4\n",
    "    data_range: float = 3.0   # sample x in [-R, R]^in_dim\n",
    "\n",
    "    # Model\n",
    "    hidden: int = 64\n",
    "    enc_layers: int = 2\n",
    "    dec_layers: int = 2\n",
    "\n",
    "    # Training\n",
    "    seed: int = 42\n",
    "    n_train: int = 50_000\n",
    "    n_val: int = 5_000\n",
    "    batch_size: int = 256\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 1e-4\n",
    "    epochs: int = 25\n",
    "\n",
    "    # IO\n",
    "    device: torch.device = device\n",
    "    model_path: str = os.path.join(_run_path, \"model.pt\")\n",
    "    probe_path: str = os.path.join(_run_path, \"embeddings_probe.npz\")\n",
    "\n",
    "cfg = Config()\n",
    "set_seed(cfg.seed)\n",
    "\n",
    "# Define your target function here. It must map [N, in_dim] -> [N, out_dim].\n",
    "# Example: f(x) = sin(||x||) returning a single output regardless of in_dim.\n",
    "def target_fn(x: torch.Tensor) -> torch.Tensor:\n",
    "    r = torch.linalg.norm(x, dim=1, keepdim=True)\n",
    "    return torch.sin(r)  # shape [N,1]\n",
    "\n",
    "writer = SummaryWriter(log_dir=_run_path)\n",
    "writer.add_text(\n",
    "    'config',\n",
    "    str(\n",
    "        dict(\n",
    "            in_dim=cfg.in_dim,\n",
    "            out_dim=cfg.out_dim,\n",
    "            embed_dim=cfg.embed_dim,\n",
    "            hidden=cfg.hidden,\n",
    "            enc_layers=cfg.enc_layers,\n",
    "            dec_layers=cfg.dec_layers,\n",
    "            data_range=cfg.data_range,\n",
    "            seed=cfg.seed,\n",
    "        )\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d53536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: online sampling, 50000 samples/epoch; Validation: 5000 samples\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Data: generic function via online sampling\n",
    "# --------------------\n",
    "train_dataset = OnlineFunctionDataset(\n",
    "    n=cfg.n_train,\n",
    "    in_dim=cfg.in_dim,\n",
    "    target_fn=target_fn,\n",
    "    data_range=cfg.data_range,\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "val_dataset = make_fixed_val_dataset(\n",
    "    n_val=cfg.n_val,\n",
    "    in_dim=cfg.in_dim,\n",
    "    target_fn=target_fn,\n",
    "    data_range=cfg.data_range,\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "print(f\"Training: online sampling, {cfg.n_train} samples/epoch; Validation: {cfg.n_val} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b0cc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SymmetricToyNet(\n",
       "  (enc): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): GELU(approximate='none')\n",
       "  )\n",
       "  (embed): Linear(in_features=64, out_features=4, bias=True)\n",
       "  (dec): Sequential(\n",
       "    (0): GELU(approximate='none')\n",
       "    (1): Linear(in_features=4, out_features=64, bias=True)\n",
       "    (2): GELU(approximate='none')\n",
       "    (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------\n",
    "# Model: Encoder -> Embedding -> Decoder (generic)\n",
    "# --------------------\n",
    "model = BottleneckMLP(\n",
    "    in_dim=cfg.in_dim,\n",
    "    out_dim=cfg.out_dim,\n",
    "    embed_dim=cfg.embed_dim,\n",
    "    hidden=cfg.hidden,\n",
    "    enc_layers=cfg.enc_layers,\n",
    "    dec_layers=cfg.dec_layers,\n",
    ").to(cfg.device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dbe778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.76660204 0.397386   1.4832675  0.7541363 ]\n",
      " [1.5072536  2.7673707  0.5099053  0.3163967 ]\n",
      " [0.74721813 0.38037446 1.404191   0.7703118 ]\n",
      " ...\n",
      " [0.78408617 0.7962326  1.3488846  0.75545484]\n",
      " [0.72979206 0.01133008 1.4043319  0.73903817]\n",
      " [0.90415114 1.1851424  1.6042862  0.7739054 ]]\n",
      "Epoch 01/25 | val MSE: 0.003577\n",
      "[[2.3480918  2.5691285  2.056397   0.97382075]\n",
      " [1.0164411  0.47309586 1.3806063  0.9433281 ]\n",
      " [2.2531257  2.803103   1.8752717  1.0170593 ]\n",
      " ...\n",
      " [2.591055   2.3546014  1.5087079  1.0067024 ]\n",
      " [1.5683738  1.2432367  1.5308281  1.0022707 ]\n",
      " [2.0241208  1.7844038  1.5353068  1.0841305 ]]\n",
      "Epoch 01/25 | val MSE: 0.003577\n",
      "[[2.3480918  2.5691285  2.056397   0.97382075]\n",
      " [1.0164411  0.47309586 1.3806063  0.9433281 ]\n",
      " [2.2531257  2.803103   1.8752717  1.0170593 ]\n",
      " ...\n",
      " [2.591055   2.3546014  1.5087079  1.0067024 ]\n",
      " [1.5683738  1.2432367  1.5308281  1.0022707 ]\n",
      " [2.0241208  1.7844038  1.5353068  1.0841305 ]]\n",
      "[[2.8172402  2.8726158  2.4462614  1.3752297 ]\n",
      " [3.1162019  3.6734495  2.1058867  1.2046729 ]\n",
      " [3.576462   4.0331464  2.6585226  1.3822592 ]\n",
      " ...\n",
      " [3.3203535  3.985652   2.278682   1.2212964 ]\n",
      " [0.85487074 0.3610004  1.2713045  1.1041802 ]\n",
      " [2.1385899  2.0036035  1.9132386  1.3178366 ]]\n",
      "[[2.8172402  2.8726158  2.4462614  1.3752297 ]\n",
      " [3.1162019  3.6734495  2.1058867  1.2046729 ]\n",
      " [3.576462   4.0331464  2.6585226  1.3822592 ]\n",
      " ...\n",
      " [3.3203535  3.985652   2.278682   1.2212964 ]\n",
      " [0.85487074 0.3610004  1.2713045  1.1041802 ]\n",
      " [2.1385899  2.0036035  1.9132386  1.3178366 ]]\n",
      "[[ 3.1867056   3.5298448   2.1844664   1.5515023 ]\n",
      " [ 3.840285    4.9591813   2.1691775   1.3703549 ]\n",
      " [ 2.4050117   1.7552104   1.7248402   1.651981  ]\n",
      " ...\n",
      " [ 3.9514906   4.158375    2.934363    1.7077307 ]\n",
      " [ 0.33596206 -0.02830497  1.136091    1.0480188 ]\n",
      " [ 0.98364484  0.5300654   1.4986126   1.211531  ]]\n",
      "[[ 3.1867056   3.5298448   2.1844664   1.5515023 ]\n",
      " [ 3.840285    4.9591813   2.1691775   1.3703549 ]\n",
      " [ 2.4050117   1.7552104   1.7248402   1.651981  ]\n",
      " ...\n",
      " [ 3.9514906   4.158375    2.934363    1.7077307 ]\n",
      " [ 0.33596206 -0.02830497  1.136091    1.0480188 ]\n",
      " [ 0.98364484  0.5300654   1.4986126   1.211531  ]]\n",
      "[[1.3752242 0.7952402 1.4986789 1.667591 ]\n",
      " [3.1442356 2.3636425 1.9835464 2.0186431]\n",
      " [4.1711903 4.1088448 2.646552  1.8521159]\n",
      " ...\n",
      " [2.11489   1.3706381 1.7580774 1.6897599]\n",
      " [4.8100524 4.387613  2.2216878 2.0688465]\n",
      " [1.80102   1.0895882 1.6572504 1.6160536]]\n",
      "[[1.3752242 0.7952402 1.4986789 1.667591 ]\n",
      " [3.1442356 2.3636425 1.9835464 2.0186431]\n",
      " [4.1711903 4.1088448 2.646552  1.8521159]\n",
      " ...\n",
      " [2.11489   1.3706381 1.7580774 1.6897599]\n",
      " [4.8100524 4.387613  2.2216878 2.0688465]\n",
      " [1.80102   1.0895882 1.6572504 1.6160536]]\n",
      "[[2.286893  1.5336488 2.0896764 1.6374927]\n",
      " [3.4738014 2.8709862 2.4604619 1.924523 ]\n",
      " [2.6392128 1.7077795 1.8967485 2.059037 ]\n",
      " ...\n",
      " [4.9641953 4.842832  3.0921888 1.8277457]\n",
      " [3.5016963 2.9885705 2.4257512 1.9180199]\n",
      " [3.1268017 2.4647796 2.4307814 1.7545409]]\n",
      "[[2.286893  1.5336488 2.0896764 1.6374927]\n",
      " [3.4738014 2.8709862 2.4604619 1.924523 ]\n",
      " [2.6392128 1.7077795 1.8967485 2.059037 ]\n",
      " ...\n",
      " [4.9641953 4.842832  3.0921888 1.8277457]\n",
      " [3.5016963 2.9885705 2.4257512 1.9180199]\n",
      " [3.1268017 2.4647796 2.4307814 1.7545409]]\n",
      "[[3.0034688  2.1361024  2.2596679  1.7680893 ]\n",
      " [1.5592535  0.76807535 1.6437707  1.6602993 ]\n",
      " [2.6878643  1.736269   2.0976217  1.8595487 ]\n",
      " ...\n",
      " [4.0480466  2.923299   2.3600388  2.360462  ]\n",
      " [1.9891764  1.083476   1.7181474  1.8877782 ]\n",
      " [2.7556107  1.8768835  2.2850995  1.7452774 ]]\n",
      "[[3.0034688  2.1361024  2.2596679  1.7680893 ]\n",
      " [1.5592535  0.76807535 1.6437707  1.6602993 ]\n",
      " [2.6878643  1.736269   2.0976217  1.8595487 ]\n",
      " ...\n",
      " [4.0480466  2.923299   2.3600388  2.360462  ]\n",
      " [1.9891764  1.083476   1.7181474  1.8877782 ]\n",
      " [2.7556107  1.8768835  2.2850995  1.7452774 ]]\n",
      "[[5.1202035 5.051063  2.6478179 1.8644502]\n",
      " [4.660002  3.9198227 2.77981   1.9573543]\n",
      " [5.6634965 5.1015277 3.4032118 2.0444868]\n",
      " ...\n",
      " [4.5008874 3.825381  2.8085277 2.07732  ]\n",
      " [3.3972344 2.4257426 2.3584182 1.9897532]\n",
      " [4.177625  3.51375   2.4752142 1.9943061]]\n",
      "[[5.1202035 5.051063  2.6478179 1.8644502]\n",
      " [4.660002  3.9198227 2.77981   1.9573543]\n",
      " [5.6634965 5.1015277 3.4032118 2.0444868]\n",
      " ...\n",
      " [4.5008874 3.825381  2.8085277 2.07732  ]\n",
      " [3.3972344 2.4257426 2.3584182 1.9897532]\n",
      " [4.177625  3.51375   2.4752142 1.9943061]]\n",
      "[[3.1091294 2.049419  2.2915986 1.8450258]\n",
      " [4.657314  3.7362776 2.5305455 2.149213 ]\n",
      " [5.4374967 4.5276437 2.9523222 2.403385 ]\n",
      " ...\n",
      " [5.5794883 4.792964  3.4459794 2.0503488]\n",
      " [2.1870906 1.162256  1.9073757 1.8438176]\n",
      " [6.4419847 5.3322544 2.7093043 2.5245216]]\n",
      "[[3.1091294 2.049419  2.2915986 1.8450258]\n",
      " [4.657314  3.7362776 2.5305455 2.149213 ]\n",
      " [5.4374967 4.5276437 2.9523222 2.403385 ]\n",
      " ...\n",
      " [5.5794883 4.792964  3.4459794 2.0503488]\n",
      " [2.1870906 1.162256  1.9073757 1.8438176]\n",
      " [6.4419847 5.3322544 2.7093043 2.5245216]]\n",
      "Epoch 05/25 | val MSE: 0.000138\n",
      "[[6.276782   5.6864285  3.330317   2.026043  ]\n",
      " [5.642133   5.1401253  2.7046914  2.031496  ]\n",
      " [1.5602751  0.70266813 1.6345739  1.807957  ]\n",
      " ...\n",
      " [4.234003   3.2550068  2.7213035  1.9183016 ]\n",
      " [4.6651845  3.5367818  2.7684004  2.3572893 ]\n",
      " [5.6705217  4.3410997  2.7264595  2.6054509 ]]\n",
      "Epoch 05/25 | val MSE: 0.000138\n",
      "[[6.276782   5.6864285  3.330317   2.026043  ]\n",
      " [5.642133   5.1401253  2.7046914  2.031496  ]\n",
      " [1.5602751  0.70266813 1.6345739  1.807957  ]\n",
      " ...\n",
      " [4.234003   3.2550068  2.7213035  1.9183016 ]\n",
      " [4.6651845  3.5367818  2.7684004  2.3572893 ]\n",
      " [5.6705217  4.3410997  2.7264595  2.6054509 ]]\n",
      "[[3.4928136  2.2088392  2.282161   2.114404  ]\n",
      " [4.533222   3.4852984  2.8131444  2.1241252 ]\n",
      " [4.6570873  3.6604557  2.5516617  2.1352901 ]\n",
      " ...\n",
      " [2.4488351  1.301067   2.0011396  1.9362957 ]\n",
      " [1.7947562  0.83394504 1.7187334  1.8901865 ]\n",
      " [5.0160265  4.3749623  2.7147954  2.0262153 ]]\n",
      "[[3.4928136  2.2088392  2.282161   2.114404  ]\n",
      " [4.533222   3.4852984  2.8131444  2.1241252 ]\n",
      " [4.6570873  3.6604557  2.5516617  2.1352901 ]\n",
      " ...\n",
      " [2.4488351  1.301067   2.0011396  1.9362957 ]\n",
      " [1.7947562  0.83394504 1.7187334  1.8901865 ]\n",
      " [5.0160265  4.3749623  2.7147954  2.0262153 ]]\n",
      "[[6.6585307 6.0349417 3.1957552 1.803294 ]\n",
      " [6.2535214 4.831785  2.6828334 2.5778983]\n",
      " [3.2529304 1.949954  2.2255864 2.0662172]\n",
      " ...\n",
      " [3.129416  1.9361231 2.3583188 1.9683396]\n",
      " [3.6021497 2.284185  2.3076968 2.112676 ]\n",
      " [5.4316382 4.5435038 2.9271693 1.9144045]]\n",
      "[[6.6585307 6.0349417 3.1957552 1.803294 ]\n",
      " [6.2535214 4.831785  2.6828334 2.5778983]\n",
      " [3.2529304 1.949954  2.2255864 2.0662172]\n",
      " ...\n",
      " [3.129416  1.9361231 2.3583188 1.9683396]\n",
      " [3.6021497 2.284185  2.3076968 2.112676 ]\n",
      " [5.4316382 4.5435038 2.9271693 1.9144045]]\n",
      "[[4.8618493 3.9081216 2.8576546 2.1459823]\n",
      " [6.3256783 5.534881  3.3617895 2.0454152]\n",
      " [4.140165  2.9671118 2.7084298 2.0677722]\n",
      " ...\n",
      " [4.0434737 2.5253394 2.3945248 2.2980373]\n",
      " [3.811697  2.3820539 2.460608  2.321892 ]\n",
      " [3.5366564 2.119023  2.2668524 2.1581383]]\n",
      "[[4.8618493 3.9081216 2.8576546 2.1459823]\n",
      " [6.3256783 5.534881  3.3617895 2.0454152]\n",
      " [4.140165  2.9671118 2.7084298 2.0677722]\n",
      " ...\n",
      " [4.0434737 2.5253394 2.3945248 2.2980373]\n",
      " [3.811697  2.3820539 2.460608  2.321892 ]\n",
      " [3.5366564 2.119023  2.2668524 2.1581383]]\n",
      "[[6.6217666  5.875898   3.3446174  2.004208  ]\n",
      " [5.1100965  4.0105815  2.6129112  2.1553154 ]\n",
      " [1.8739009  0.84087837 1.688389   2.0958629 ]\n",
      " ...\n",
      " [5.963489   4.98398    3.424149   2.1021512 ]\n",
      " [4.3827596  3.255211   2.6857631  1.9487021 ]\n",
      " [6.5379224  6.289077   2.8769703  1.8150175 ]]\n",
      "[[6.6217666  5.875898   3.3446174  2.004208  ]\n",
      " [5.1100965  4.0105815  2.6129112  2.1553154 ]\n",
      " [1.8739009  0.84087837 1.688389   2.0958629 ]\n",
      " ...\n",
      " [5.963489   4.98398    3.424149   2.1021512 ]\n",
      " [4.3827596  3.255211   2.6857631  1.9487021 ]\n",
      " [6.5379224  6.289077   2.8769703  1.8150175 ]]\n",
      "[[3.426739  1.8795539 2.2002482 2.3530579]\n",
      " [7.160992  5.641983  2.7687163 2.5326085]\n",
      " [3.6879308 2.1585572 2.3005447 2.2245104]\n",
      " ...\n",
      " [2.7744246 1.4587042 2.1353428 1.9816344]\n",
      " [5.3532705 4.2053857 2.9091358 2.2897925]\n",
      " [5.2303796 3.5284865 2.5885825 2.5974085]]\n",
      "[[3.426739  1.8795539 2.2002482 2.3530579]\n",
      " [7.160992  5.641983  2.7687163 2.5326085]\n",
      " [3.6879308 2.1585572 2.3005447 2.2245104]\n",
      " ...\n",
      " [2.7744246 1.4587042 2.1353428 1.9816344]\n",
      " [5.3532705 4.2053857 2.9091358 2.2897925]\n",
      " [5.2303796 3.5284865 2.5885825 2.5974085]]\n",
      "[[3.8560324 2.6065388 2.555049  1.950811 ]\n",
      " [4.141877  2.47752   2.4189944 2.3626785]\n",
      " [6.3546505 4.7633915 2.8471293 2.5232992]\n",
      " ...\n",
      " [5.86812   4.3226824 2.8531587 2.6316302]\n",
      " [5.334303  3.7190905 2.6805954 2.4599001]\n",
      " [6.178259  4.6554327 2.8289232 2.4658847]]\n",
      "[[3.8560324 2.6065388 2.555049  1.950811 ]\n",
      " [4.141877  2.47752   2.4189944 2.3626785]\n",
      " [6.3546505 4.7633915 2.8471293 2.5232992]\n",
      " ...\n",
      " [5.86812   4.3226824 2.8531587 2.6316302]\n",
      " [5.334303  3.7190905 2.6805954 2.4599001]\n",
      " [6.178259  4.6554327 2.8289232 2.4658847]]\n",
      "[[6.1286263 5.140358  3.4389277 2.0371299]\n",
      " [5.382775  3.6112573 2.6395106 2.5720975]\n",
      " [1.4909115 0.5713579 1.6217494 1.9257159]\n",
      " ...\n",
      " [6.1493483 5.160046  3.355256  2.0986679]\n",
      " [4.909261  3.2113636 2.5878077 2.4385676]\n",
      " [2.5754428 1.3291115 2.0966845 2.0017529]]\n",
      "[[6.1286263 5.140358  3.4389277 2.0371299]\n",
      " [5.382775  3.6112573 2.6395106 2.5720975]\n",
      " [1.4909115 0.5713579 1.6217494 1.9257159]\n",
      " ...\n",
      " [6.1493483 5.160046  3.355256  2.0986679]\n",
      " [4.909261  3.2113636 2.5878077 2.4385676]\n",
      " [2.5754428 1.3291115 2.0966845 2.0017529]]\n",
      "[[4.7467275 3.3714542 2.74055   2.2912676]\n",
      " [4.1953254 2.7624977 2.6061811 2.221242 ]\n",
      " [2.5857644 1.3201996 2.1212676 1.9543027]\n",
      " ...\n",
      " [4.2890635 3.0052154 2.8164163 2.0232506]\n",
      " [3.8443773 2.4558213 2.556801  2.0878975]\n",
      " [4.6896343 3.429676  2.8299348 2.180696 ]]\n",
      "[[4.7467275 3.3714542 2.74055   2.2912676]\n",
      " [4.1953254 2.7624977 2.6061811 2.221242 ]\n",
      " [2.5857644 1.3201996 2.1212676 1.9543027]\n",
      " ...\n",
      " [4.2890635 3.0052154 2.8164163 2.0232506]\n",
      " [3.8443773 2.4558213 2.556801  2.0878975]\n",
      " [4.6896343 3.429676  2.8299348 2.180696 ]]\n",
      "[[6.0207148 4.578752  2.7617674 2.2892127]\n",
      " [5.556906  4.390263  3.266522  2.1303582]\n",
      " [4.985517  3.1929202 2.5910451 2.4565146]\n",
      " ...\n",
      " [5.8150063 4.8392744 3.047819  1.9199659]\n",
      " [6.1385417 4.768559  2.77532   2.249847 ]\n",
      " [7.151646  5.5089135 2.8087218 2.5365386]]\n",
      "[[6.0207148 4.578752  2.7617674 2.2892127]\n",
      " [5.556906  4.390263  3.266522  2.1303582]\n",
      " [4.985517  3.1929202 2.5910451 2.4565146]\n",
      " ...\n",
      " [5.8150063 4.8392744 3.047819  1.9199659]\n",
      " [6.1385417 4.768559  2.77532   2.249847 ]\n",
      " [7.151646  5.5089135 2.8087218 2.5365386]]\n",
      "Epoch 10/25 | val MSE: 0.000093\n",
      "Epoch 10/25 | val MSE: 0.000093\n",
      "[[7.861866  6.2480154 2.7368307 2.367407 ]\n",
      " [2.4990172 1.1499604 1.8905358 2.1932414]\n",
      " [5.04389   3.8412895 2.8267365 2.0595381]\n",
      " ...\n",
      " [4.7408347 3.3314817 2.5299592 2.144743 ]\n",
      " [7.0883565 6.248311  3.3415937 1.9674042]\n",
      " [6.1119184 5.0816774 3.3794813 2.0270536]]\n",
      "[[7.861866  6.2480154 2.7368307 2.367407 ]\n",
      " [2.4990172 1.1499604 1.8905358 2.1932414]\n",
      " [5.04389   3.8412895 2.8267365 2.0595381]\n",
      " ...\n",
      " [4.7408347 3.3314817 2.5299592 2.144743 ]\n",
      " [7.0883565 6.248311  3.3415937 1.9674042]\n",
      " [6.1119184 5.0816774 3.3794813 2.0270536]]\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Training\n",
    "# --------------------\n",
    "result = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    epochs=cfg.epochs,\n",
    "    lr=cfg.lr,\n",
    "    weight_decay=cfg.weight_decay,\n",
    "    writer=writer,\n",
    "    device=cfg.device,\n",
    "    log_hist_every=100,\n",
    ")\n",
    "\n",
    "print(f\"Best val MSE: {result['best_val']:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75d0738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: /Users/noah-everett/Documents/Research/Embedding-Analysis/runs/symmetry_run_1/model.pt\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Save model + handy metadata\n",
    "# --------------------\n",
    "payload = {\n",
    "    \"state_dict\": model.state_dict(),\n",
    "    \"config\": {\n",
    "        \"in_dim\": cfg.in_dim,\n",
    "        \"out_dim\": cfg.out_dim,\n",
    "        \"hidden\": cfg.hidden,\n",
    "        \"embed_dim\": cfg.embed_dim,\n",
    "        \"enc_layers\": cfg.enc_layers,\n",
    "        \"dec_layers\": cfg.dec_layers,\n",
    "        \"data_range\": cfg.data_range,\n",
    "        \"seed\": cfg.seed,\n",
    "        \"target_fn\": getattr(target_fn, \"__name__\", str(target_fn)),\n",
    "    },\n",
    "    \"model_class\": \"BottleneckMLP\",\n",
    "}\n",
    "torch.save(payload, cfg.model_path)\n",
    "print(f\"Saved model to: {os.path.abspath(cfg.model_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38dc4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embedding grid to: /Users/noah-everett/Documents/Research/Embedding-Analysis/runs/symmetry_run_1/embeddings_grid.npz\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Save probe embeddings for downstream analysis (works for any in/out/embed sizes)\n",
    "# --------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Random probe inputs in the training domain\n",
    "    N_probe = 10240\n",
    "    X = np.random.uniform(-cfg.data_range, cfg.data_range, size=(N_probe, cfg.in_dim)).astype(np.float32)\n",
    "\n",
    "    xb = torch.from_numpy(X).to(cfg.device)\n",
    "    pred, z = model(xb)\n",
    "    pred = pred.cpu().numpy()\n",
    "    Z = z.cpu().numpy()\n",
    "\n",
    "    try:\n",
    "        # Log embeddings to TensorBoard projector (works for any dimensionality)\n",
    "        writer.add_embedding(torch.from_numpy(Z), global_step=0, tag='embeddings/probe')\n",
    "        if cfg.embed_dim == 2:\n",
    "            import matplotlib.pyplot as plt\n",
    "            r = np.linalg.norm(X, axis=1)\n",
    "            fig, ax = plt.subplots(figsize=(6, 6))\n",
    "            sc = ax.scatter(Z[:, 0], Z[:, 1], c=r, s=5, cmap='viridis')\n",
    "            ax.set_title('Embeddings (colored by ||x||)')\n",
    "            ax.set_xlabel('z0')\n",
    "            ax.set_ylabel('z1')\n",
    "            plt.colorbar(sc, ax=ax, label='||x||')\n",
    "            writer.add_figure('embeddings/2d_scatter', fig)\n",
    "            plt.close(fig)\n",
    "    except Exception as e:\n",
    "        print('Warning: failed to log embeddings to TensorBoard:', e)\n",
    "\n",
    "# Save everything needed for downstream math/plots (general)\n",
    "np.savez_compressed(\n",
    "    cfg.probe_path,\n",
    "    x=X,                # [N,in_dim] inputs in input space\n",
    "    z=Z,                # [N,embed_dim] embeddings\n",
    "    pred=pred           # [N,out_dim] predicted f(x)\n",
    ")\n",
    "print(f\"Saved probe embeddings to: {os.path.abspath(cfg.probe_path)}\")\n",
    "\n",
    "writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_3_11_5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

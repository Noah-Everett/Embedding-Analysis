{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "680a2ed7",
   "metadata": {},
   "source": [
    "\n",
    "# Symmetric Function Embedding (PyTorch)\n",
    "\n",
    "This notebook trains a tiny encoder–decoder MLP on a **rotationally symmetric** target function $f(\\mathbf{x}) = \\sin(|\\mathbf{x}|)$.\n",
    "\n",
    "It includes a low-dimensional **embedding bottleneck** you can analyze, and saves:\n",
    "- `toy_symmetry_model.pt` – the trained model (state dict + metadata)\n",
    "- `embeddings_grid.npz` – a polar grid of inputs with the model's embeddings and predictions\n",
    "\n",
    "> Tip: tweak `cfg.embed_dim` and the target function to explore different symmetries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e06efc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.8.0\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Setup & Config\n",
    "# --------------------\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "if getattr(torch.backends, \"mps\", None) is not None and torch.backends.mps.is_available() and getattr(torch.backends.mps, 'is_built', lambda: True)():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "_run_path_number = -1\n",
    "_run_path = ''\n",
    "while os.path.exists(_run_path) or _run_path_number < 0:\n",
    "    _run_path_number += 1\n",
    "    _run_path = os.path.join('runs', f'symmetry_run_{_run_path_number}')\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    seed: int = 42\n",
    "    n_train: int = 50_000\n",
    "    n_val: int = 5_000\n",
    "    batch_size: int = 256\n",
    "    lr: float = 1e-3\n",
    "    epochs: int = 25\n",
    "    hidden: int = 64\n",
    "    embed_dim: int = 2   # embedding space size to analyze\n",
    "    data_range: float = 3.0  # sample x,y uniformly in [-R, R]\n",
    "    device: torch.device = device\n",
    "    model_path: str = os.path.join(_run_path, \"model.pt\")\n",
    "    emb_grid_path: str = os.path.join(_run_path, \"embeddings_grid.npz\")\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(cfg.seed)\n",
    "\n",
    "# generate a small random suffix; use integer literal for upper bound to avoid TypeError\n",
    "writer = SummaryWriter(log_dir=_run_path)\n",
    "writer.add_text('config', str(dict(hidden=cfg.hidden, embed_dim=cfg.embed_dim, data_range=cfg.data_range, seed=cfg.seed)))\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d53536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: online sampling, 50000 samples/epoch; Validation: 5000 samples\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Data: rotational symmetry (online training)\n",
    "# Target: f(x, y) = sin(sqrt(x^2 + y^2))\n",
    "# --------------------\n",
    "class RandomXYDataset(torch.utils.data.IterableDataset):\n",
    "    \"\"\"Iterable dataset that samples (x,y) pairs uniformly in [-R, R]^2 each epoch.\"\"\"\n",
    "    def __init__(self, n, R):\n",
    "        super().__init__()\n",
    "        self.n = int(n)\n",
    "        self.R = float(R)\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Generate all samples for this epoch and yield them in random order.\n",
    "        xy = np.random.uniform(-self.R, self.R, size=(self.n, 2)).astype(np.float32)\n",
    "        r = np.linalg.norm(xy, axis=1, keepdims=True).astype(np.float32)\n",
    "        y = np.sin(r).astype(np.float32)\n",
    "\n",
    "        # Optionally shuffle order so batches vary each epoch\n",
    "        idx = np.arange(self.n)\n",
    "        np.random.shuffle(idx)\n",
    "        for i in idx:\n",
    "            yield torch.from_numpy(xy[i]), torch.from_numpy(y[i])\n",
    "\n",
    "# Validation set remains pre-sampled for stable evaluation\n",
    "x_val = np.random.uniform(-cfg.data_range, cfg.data_range, size=(cfg.n_val, 2)).astype(np.float32)\n",
    "r_val = np.linalg.norm(x_val, axis=1, keepdims=True).astype(np.float32)\n",
    "y_val = np.sin(r_val).astype(np.float32)\n",
    "\n",
    "train_dataset = RandomXYDataset(cfg.n_train, cfg.data_range)\n",
    "train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=False, drop_last=True)\n",
    "val_loader = DataLoader(TensorDataset(torch.from_numpy(x_val), torch.from_numpy(y_val)), batch_size=1024, shuffle=False)\n",
    "\n",
    "# Print dataset sizes for confirmation\n",
    "print(f\"Training: online sampling, {cfg.n_train} samples/epoch; Validation: {len(x_val)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6b0cc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SymmetricToyNet(\n",
       "  (enc): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): GELU(approximate='none')\n",
       "  )\n",
       "  (embed): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (dec): Sequential(\n",
       "    (0): GELU(approximate='none')\n",
       "    (1): Linear(in_features=2, out_features=64, bias=True)\n",
       "    (2): GELU(approximate='none')\n",
       "    (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --------------------\n",
    "# Model: Encoder -> Embedding -> Decoder\n",
    "# --------------------\n",
    "class SymmetricToyNet(nn.Module):\n",
    "    def __init__(self, in_dim=2, hidden=64, embed_dim=2):\n",
    "        super().__init__()\n",
    "        # encoder\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        # embedding (bottleneck)\n",
    "        self.embed = nn.Linear(hidden, embed_dim)\n",
    "\n",
    "        # decoder\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim, hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden, 1),\n",
    "        )\n",
    "\n",
    "        # Kaiming init\n",
    "        def init(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight, a=math.sqrt(5))\n",
    "                if m.bias is not None:\n",
    "                    fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n",
    "                    bound = 1 / math.sqrt(fan_in)\n",
    "                    nn.init.uniform_(m.bias, -bound, bound)\n",
    "        self.apply(init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.enc(x)\n",
    "        z = self.embed(h)           # <-- embedding to analyze\n",
    "        out = self.dec(z)\n",
    "        return out, z\n",
    "\n",
    "model = SymmetricToyNet(hidden=cfg.hidden, embed_dim=cfg.embed_dim).to(cfg.device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24dbe778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/25 | val MSE: 0.009410\n",
      "Epoch 05/25 | val MSE: 0.000247\n",
      "Epoch 05/25 | val MSE: 0.000247\n",
      "Epoch 10/25 | val MSE: 0.000099\n",
      "Epoch 10/25 | val MSE: 0.000099\n",
      "Epoch 15/25 | val MSE: 0.000053\n",
      "Epoch 15/25 | val MSE: 0.000053\n",
      "Epoch 20/25 | val MSE: 0.000066\n",
      "Epoch 20/25 | val MSE: 0.000066\n",
      "Epoch 25/25 | val MSE: 0.000033\n",
      "Best val MSE: 0.000033\n",
      "Epoch 25/25 | val MSE: 0.000033\n",
      "Best val MSE: 0.000033\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Training\n",
    "# --------------------\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=1e-4)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    total, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(cfg.device)\n",
    "            yb = yb.to(cfg.device)\n",
    "            pred, _ = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            total += loss.item() * xb.size(0)\n",
    "            n += xb.size(0)\n",
    "    return total / n\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "for epoch in range(1, cfg.epochs + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    batch_count = 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(cfg.device)      # [B,2]\n",
    "        yb = yb.to(cfg.device)      # [B,1]\n",
    "        pred, z = model(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        global_step += 1\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "        batch_count += xb.size(0)\n",
    "        writer.add_scalar('train/batch_loss', loss.item(), global_step)\n",
    "        if global_step % 100 == 0:\n",
    "            writer.add_histogram('embed/batch', z.detach().cpu().numpy(), global_step)\n",
    "\n",
    "    epoch_loss = running_loss / batch_count if batch_count else 0.0\n",
    "    writer.add_scalar('train/epoch_loss', epoch_loss, epoch)\n",
    "\n",
    "    val_loss = evaluate()\n",
    "    best_val = min(best_val, val_loss)\n",
    "\n",
    "    writer.add_scalar('val/epoch_loss', val_loss, epoch)\n",
    "    for i, param_group in enumerate(opt.param_groups):\n",
    "        writer.add_scalar(f'lr/group_{i}', param_group.get('lr', 0.0), epoch)\n",
    "\n",
    "    if epoch % 5 == 0 or epoch == 1 or epoch == cfg.epochs:\n",
    "        print(f\"Epoch {epoch:02d}/{cfg.epochs} | val MSE: {val_loss:.6f}\")\n",
    "\n",
    "print(f\"Best val MSE: {best_val:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b75d0738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: /Users/noah-everett/Documents/Research/Embedding-Analysis/runs/symmetry_run_0/model.pt\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Save model + handy metadata\n",
    "# --------------------\n",
    "payload = {\n",
    "    \"state_dict\": model.state_dict(),\n",
    "    \"config\": {\n",
    "        \"hidden\": cfg.hidden,\n",
    "        \"embed_dim\": cfg.embed_dim,\n",
    "        \"target_fn\": \"f(x,y) = sin(||[x,y]||)\",\n",
    "        \"data_range\": cfg.data_range,\n",
    "        \"normalization\": \"none\",\n",
    "        \"seed\": cfg.seed,\n",
    "    },\n",
    "    \"model_class\": \"SymmetricToyNet\",\n",
    "}\n",
    "torch.save(payload, cfg.model_path)\n",
    "print(f\"Saved model to: {os.path.abspath(cfg.model_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c38dc4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embedding grid to: /Users/noah-everett/Documents/Research/Embedding-Analysis/runs/symmetry_run_0/embeddings_grid.npz\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Save embeddings for a polar grid (for downstream analysis)\n",
    "# --------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # build a polar grid; map to xy; get embeddings z\n",
    "    radii = np.linspace(0.0, cfg.data_range * math.sqrt(2), 80).astype(np.float32)\n",
    "    thetas = np.linspace(0.0, 2 * math.pi, 128, endpoint=False).astype(np.float32)\n",
    "    R, T = np.meshgrid(radii, thetas, indexing='ij')\n",
    "    X = (R * np.cos(T)).reshape(-1)\n",
    "    Y = (R * np.sin(T)).reshape(-1)\n",
    "    XY = np.stack([X, Y], axis=1).astype(np.float32)\n",
    "\n",
    "    xb = torch.from_numpy(XY).to(cfg.device)\n",
    "    pred, z = model(xb)\n",
    "    pred = pred.squeeze(-1).cpu().numpy()\n",
    "    Z = z.cpu().numpy()\n",
    "\n",
    "    try:\n",
    "        radii_flat = R.reshape(-1)\n",
    "        writer.add_embedding(torch.from_numpy(Z), metadata=[str(float(r)) for r in radii_flat], global_step=0, tag='embeddings/grid')\n",
    "        if cfg.embed_dim == 2:\n",
    "            fig, ax = plt.subplots(figsize=(6, 6))\n",
    "            sc = ax.scatter(Z[:, 0], Z[:, 1], c=radii_flat, s=5, cmap='viridis')\n",
    "            ax.set_title('Embeddings (colored by radius)')\n",
    "            ax.set_xlabel('z0')\n",
    "            ax.set_ylabel('z1')\n",
    "            plt.colorbar(sc, ax=ax, label='radius')\n",
    "            writer.add_figure('embeddings/2d_scatter', fig)\n",
    "            plt.close(fig)\n",
    "    except Exception as e:\n",
    "        print('Warning: failed to log embeddings to TensorBoard:', e)\n",
    "\n",
    "# Save everything needed for downstream math/plots\n",
    "np.savez_compressed(\n",
    "    cfg.emb_grid_path,\n",
    "    xy=XY,               # [N,2] positions in input space\n",
    "    z=Z,                 # [N,embed_dim] embeddings\n",
    "    pred=pred,           # [N] predicted f(x)\n",
    "    radii=R.reshape(-1), # [N] radius used to generate XY\n",
    "    thetas=T.reshape(-1) # [N] angle used to generate XY\n",
    ")\n",
    "print(f\"Saved embedding grid to: {os.path.abspath(cfg.emb_grid_path)}\")\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_3_11_5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
